{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-02T06:45:38.165489100Z",
     "start_time": "2023-11-02T06:45:38.155569500Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from icecream import ic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [],
   "source": [
    "data = load_iris()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T06:45:38.357142700Z",
     "start_time": "2023-11-02T06:45:38.349290300Z"
    }
   },
   "id": "5ff24399220a3cd1"
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[5.1, 3.5, 1.4, 0.2],\n       [4.9, 3. , 1.4, 0.2],\n       [4.7, 3.2, 1.3, 0.2],\n       [4.6, 3.1, 1.5, 0.2],\n       [5. , 3.6, 1.4, 0.2],\n       [5.4, 3.9, 1.7, 0.4],\n       [4.6, 3.4, 1.4, 0.3],\n       [5. , 3.4, 1.5, 0.2],\n       [4.4, 2.9, 1.4, 0.2],\n       [4.9, 3.1, 1.5, 0.1],\n       [5.4, 3.7, 1.5, 0.2],\n       [4.8, 3.4, 1.6, 0.2],\n       [4.8, 3. , 1.4, 0.1],\n       [4.3, 3. , 1.1, 0.1],\n       [5.8, 4. , 1.2, 0.2],\n       [5.7, 4.4, 1.5, 0.4],\n       [5.4, 3.9, 1.3, 0.4],\n       [5.1, 3.5, 1.4, 0.3],\n       [5.7, 3.8, 1.7, 0.3],\n       [5.1, 3.8, 1.5, 0.3],\n       [5.4, 3.4, 1.7, 0.2],\n       [5.1, 3.7, 1.5, 0.4],\n       [4.6, 3.6, 1. , 0.2],\n       [5.1, 3.3, 1.7, 0.5],\n       [4.8, 3.4, 1.9, 0.2],\n       [5. , 3. , 1.6, 0.2],\n       [5. , 3.4, 1.6, 0.4],\n       [5.2, 3.5, 1.5, 0.2],\n       [5.2, 3.4, 1.4, 0.2],\n       [4.7, 3.2, 1.6, 0.2],\n       [4.8, 3.1, 1.6, 0.2],\n       [5.4, 3.4, 1.5, 0.4],\n       [5.2, 4.1, 1.5, 0.1],\n       [5.5, 4.2, 1.4, 0.2],\n       [4.9, 3.1, 1.5, 0.2],\n       [5. , 3.2, 1.2, 0.2],\n       [5.5, 3.5, 1.3, 0.2],\n       [4.9, 3.6, 1.4, 0.1],\n       [4.4, 3. , 1.3, 0.2],\n       [5.1, 3.4, 1.5, 0.2],\n       [5. , 3.5, 1.3, 0.3],\n       [4.5, 2.3, 1.3, 0.3],\n       [4.4, 3.2, 1.3, 0.2],\n       [5. , 3.5, 1.6, 0.6],\n       [5.1, 3.8, 1.9, 0.4],\n       [4.8, 3. , 1.4, 0.3],\n       [5.1, 3.8, 1.6, 0.2],\n       [4.6, 3.2, 1.4, 0.2],\n       [5.3, 3.7, 1.5, 0.2],\n       [5. , 3.3, 1.4, 0.2],\n       [7. , 3.2, 4.7, 1.4],\n       [6.4, 3.2, 4.5, 1.5],\n       [6.9, 3.1, 4.9, 1.5],\n       [5.5, 2.3, 4. , 1.3],\n       [6.5, 2.8, 4.6, 1.5],\n       [5.7, 2.8, 4.5, 1.3],\n       [6.3, 3.3, 4.7, 1.6],\n       [4.9, 2.4, 3.3, 1. ],\n       [6.6, 2.9, 4.6, 1.3],\n       [5.2, 2.7, 3.9, 1.4],\n       [5. , 2. , 3.5, 1. ],\n       [5.9, 3. , 4.2, 1.5],\n       [6. , 2.2, 4. , 1. ],\n       [6.1, 2.9, 4.7, 1.4],\n       [5.6, 2.9, 3.6, 1.3],\n       [6.7, 3.1, 4.4, 1.4],\n       [5.6, 3. , 4.5, 1.5],\n       [5.8, 2.7, 4.1, 1. ],\n       [6.2, 2.2, 4.5, 1.5],\n       [5.6, 2.5, 3.9, 1.1],\n       [5.9, 3.2, 4.8, 1.8],\n       [6.1, 2.8, 4. , 1.3],\n       [6.3, 2.5, 4.9, 1.5],\n       [6.1, 2.8, 4.7, 1.2],\n       [6.4, 2.9, 4.3, 1.3],\n       [6.6, 3. , 4.4, 1.4],\n       [6.8, 2.8, 4.8, 1.4],\n       [6.7, 3. , 5. , 1.7],\n       [6. , 2.9, 4.5, 1.5],\n       [5.7, 2.6, 3.5, 1. ],\n       [5.5, 2.4, 3.8, 1.1],\n       [5.5, 2.4, 3.7, 1. ],\n       [5.8, 2.7, 3.9, 1.2],\n       [6. , 2.7, 5.1, 1.6],\n       [5.4, 3. , 4.5, 1.5],\n       [6. , 3.4, 4.5, 1.6],\n       [6.7, 3.1, 4.7, 1.5],\n       [6.3, 2.3, 4.4, 1.3],\n       [5.6, 3. , 4.1, 1.3],\n       [5.5, 2.5, 4. , 1.3],\n       [5.5, 2.6, 4.4, 1.2],\n       [6.1, 3. , 4.6, 1.4],\n       [5.8, 2.6, 4. , 1.2],\n       [5. , 2.3, 3.3, 1. ],\n       [5.6, 2.7, 4.2, 1.3],\n       [5.7, 3. , 4.2, 1.2],\n       [5.7, 2.9, 4.2, 1.3],\n       [6.2, 2.9, 4.3, 1.3],\n       [5.1, 2.5, 3. , 1.1],\n       [5.7, 2.8, 4.1, 1.3],\n       [6.3, 3.3, 6. , 2.5],\n       [5.8, 2.7, 5.1, 1.9],\n       [7.1, 3. , 5.9, 2.1],\n       [6.3, 2.9, 5.6, 1.8],\n       [6.5, 3. , 5.8, 2.2],\n       [7.6, 3. , 6.6, 2.1],\n       [4.9, 2.5, 4.5, 1.7],\n       [7.3, 2.9, 6.3, 1.8],\n       [6.7, 2.5, 5.8, 1.8],\n       [7.2, 3.6, 6.1, 2.5],\n       [6.5, 3.2, 5.1, 2. ],\n       [6.4, 2.7, 5.3, 1.9],\n       [6.8, 3. , 5.5, 2.1],\n       [5.7, 2.5, 5. , 2. ],\n       [5.8, 2.8, 5.1, 2.4],\n       [6.4, 3.2, 5.3, 2.3],\n       [6.5, 3. , 5.5, 1.8],\n       [7.7, 3.8, 6.7, 2.2],\n       [7.7, 2.6, 6.9, 2.3],\n       [6. , 2.2, 5. , 1.5],\n       [6.9, 3.2, 5.7, 2.3],\n       [5.6, 2.8, 4.9, 2. ],\n       [7.7, 2.8, 6.7, 2. ],\n       [6.3, 2.7, 4.9, 1.8],\n       [6.7, 3.3, 5.7, 2.1],\n       [7.2, 3.2, 6. , 1.8],\n       [6.2, 2.8, 4.8, 1.8],\n       [6.1, 3. , 4.9, 1.8],\n       [6.4, 2.8, 5.6, 2.1],\n       [7.2, 3. , 5.8, 1.6],\n       [7.4, 2.8, 6.1, 1.9],\n       [7.9, 3.8, 6.4, 2. ],\n       [6.4, 2.8, 5.6, 2.2],\n       [6.3, 2.8, 5.1, 1.5],\n       [6.1, 2.6, 5.6, 1.4],\n       [7.7, 3. , 6.1, 2.3],\n       [6.3, 3.4, 5.6, 2.4],\n       [6.4, 3.1, 5.5, 1.8],\n       [6. , 3. , 4.8, 1.8],\n       [6.9, 3.1, 5.4, 2.1],\n       [6.7, 3.1, 5.6, 2.4],\n       [6.9, 3.1, 5.1, 2.3],\n       [5.8, 2.7, 5.1, 1.9],\n       [6.8, 3.2, 5.9, 2.3],\n       [6.7, 3.3, 5.7, 2.5],\n       [6.7, 3. , 5.2, 2.3],\n       [6.3, 2.5, 5. , 1.9],\n       [6.5, 3. , 5.2, 2. ],\n       [6.2, 3.4, 5.4, 2.3],\n       [5.9, 3. , 5.1, 1.8]])"
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = data.data\n",
    "X_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T06:45:38.544074800Z",
     "start_time": "2023-11-02T06:45:38.533816500Z"
    }
   },
   "id": "5ca8487844f74246"
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.22222222, 0.625     , 0.06779661, 0.04166667],\n       [0.16666667, 0.41666667, 0.06779661, 0.04166667],\n       [0.11111111, 0.5       , 0.05084746, 0.04166667],\n       [0.08333333, 0.45833333, 0.08474576, 0.04166667],\n       [0.19444444, 0.66666667, 0.06779661, 0.04166667],\n       [0.30555556, 0.79166667, 0.11864407, 0.125     ],\n       [0.08333333, 0.58333333, 0.06779661, 0.08333333],\n       [0.19444444, 0.58333333, 0.08474576, 0.04166667],\n       [0.02777778, 0.375     , 0.06779661, 0.04166667],\n       [0.16666667, 0.45833333, 0.08474576, 0.        ],\n       [0.30555556, 0.70833333, 0.08474576, 0.04166667],\n       [0.13888889, 0.58333333, 0.10169492, 0.04166667],\n       [0.13888889, 0.41666667, 0.06779661, 0.        ],\n       [0.        , 0.41666667, 0.01694915, 0.        ],\n       [0.41666667, 0.83333333, 0.03389831, 0.04166667],\n       [0.38888889, 1.        , 0.08474576, 0.125     ],\n       [0.30555556, 0.79166667, 0.05084746, 0.125     ],\n       [0.22222222, 0.625     , 0.06779661, 0.08333333],\n       [0.38888889, 0.75      , 0.11864407, 0.08333333],\n       [0.22222222, 0.75      , 0.08474576, 0.08333333],\n       [0.30555556, 0.58333333, 0.11864407, 0.04166667],\n       [0.22222222, 0.70833333, 0.08474576, 0.125     ],\n       [0.08333333, 0.66666667, 0.        , 0.04166667],\n       [0.22222222, 0.54166667, 0.11864407, 0.16666667],\n       [0.13888889, 0.58333333, 0.15254237, 0.04166667],\n       [0.19444444, 0.41666667, 0.10169492, 0.04166667],\n       [0.19444444, 0.58333333, 0.10169492, 0.125     ],\n       [0.25      , 0.625     , 0.08474576, 0.04166667],\n       [0.25      , 0.58333333, 0.06779661, 0.04166667],\n       [0.11111111, 0.5       , 0.10169492, 0.04166667],\n       [0.13888889, 0.45833333, 0.10169492, 0.04166667],\n       [0.30555556, 0.58333333, 0.08474576, 0.125     ],\n       [0.25      , 0.875     , 0.08474576, 0.        ],\n       [0.33333333, 0.91666667, 0.06779661, 0.04166667],\n       [0.16666667, 0.45833333, 0.08474576, 0.04166667],\n       [0.19444444, 0.5       , 0.03389831, 0.04166667],\n       [0.33333333, 0.625     , 0.05084746, 0.04166667],\n       [0.16666667, 0.66666667, 0.06779661, 0.        ],\n       [0.02777778, 0.41666667, 0.05084746, 0.04166667],\n       [0.22222222, 0.58333333, 0.08474576, 0.04166667],\n       [0.19444444, 0.625     , 0.05084746, 0.08333333],\n       [0.05555556, 0.125     , 0.05084746, 0.08333333],\n       [0.02777778, 0.5       , 0.05084746, 0.04166667],\n       [0.19444444, 0.625     , 0.10169492, 0.20833333],\n       [0.22222222, 0.75      , 0.15254237, 0.125     ],\n       [0.13888889, 0.41666667, 0.06779661, 0.08333333],\n       [0.22222222, 0.75      , 0.10169492, 0.04166667],\n       [0.08333333, 0.5       , 0.06779661, 0.04166667],\n       [0.27777778, 0.70833333, 0.08474576, 0.04166667],\n       [0.19444444, 0.54166667, 0.06779661, 0.04166667],\n       [0.75      , 0.5       , 0.62711864, 0.54166667],\n       [0.58333333, 0.5       , 0.59322034, 0.58333333],\n       [0.72222222, 0.45833333, 0.66101695, 0.58333333],\n       [0.33333333, 0.125     , 0.50847458, 0.5       ],\n       [0.61111111, 0.33333333, 0.61016949, 0.58333333],\n       [0.38888889, 0.33333333, 0.59322034, 0.5       ],\n       [0.55555556, 0.54166667, 0.62711864, 0.625     ],\n       [0.16666667, 0.16666667, 0.38983051, 0.375     ],\n       [0.63888889, 0.375     , 0.61016949, 0.5       ],\n       [0.25      , 0.29166667, 0.49152542, 0.54166667],\n       [0.19444444, 0.        , 0.42372881, 0.375     ],\n       [0.44444444, 0.41666667, 0.54237288, 0.58333333],\n       [0.47222222, 0.08333333, 0.50847458, 0.375     ],\n       [0.5       , 0.375     , 0.62711864, 0.54166667],\n       [0.36111111, 0.375     , 0.44067797, 0.5       ],\n       [0.66666667, 0.45833333, 0.57627119, 0.54166667],\n       [0.36111111, 0.41666667, 0.59322034, 0.58333333],\n       [0.41666667, 0.29166667, 0.52542373, 0.375     ],\n       [0.52777778, 0.08333333, 0.59322034, 0.58333333],\n       [0.36111111, 0.20833333, 0.49152542, 0.41666667],\n       [0.44444444, 0.5       , 0.6440678 , 0.70833333],\n       [0.5       , 0.33333333, 0.50847458, 0.5       ],\n       [0.55555556, 0.20833333, 0.66101695, 0.58333333],\n       [0.5       , 0.33333333, 0.62711864, 0.45833333],\n       [0.58333333, 0.375     , 0.55932203, 0.5       ],\n       [0.63888889, 0.41666667, 0.57627119, 0.54166667],\n       [0.69444444, 0.33333333, 0.6440678 , 0.54166667],\n       [0.66666667, 0.41666667, 0.6779661 , 0.66666667],\n       [0.47222222, 0.375     , 0.59322034, 0.58333333],\n       [0.38888889, 0.25      , 0.42372881, 0.375     ],\n       [0.33333333, 0.16666667, 0.47457627, 0.41666667],\n       [0.33333333, 0.16666667, 0.45762712, 0.375     ],\n       [0.41666667, 0.29166667, 0.49152542, 0.45833333],\n       [0.47222222, 0.29166667, 0.69491525, 0.625     ],\n       [0.30555556, 0.41666667, 0.59322034, 0.58333333],\n       [0.47222222, 0.58333333, 0.59322034, 0.625     ],\n       [0.66666667, 0.45833333, 0.62711864, 0.58333333],\n       [0.55555556, 0.125     , 0.57627119, 0.5       ],\n       [0.36111111, 0.41666667, 0.52542373, 0.5       ],\n       [0.33333333, 0.20833333, 0.50847458, 0.5       ],\n       [0.33333333, 0.25      , 0.57627119, 0.45833333],\n       [0.5       , 0.41666667, 0.61016949, 0.54166667],\n       [0.41666667, 0.25      , 0.50847458, 0.45833333],\n       [0.19444444, 0.125     , 0.38983051, 0.375     ],\n       [0.36111111, 0.29166667, 0.54237288, 0.5       ],\n       [0.38888889, 0.41666667, 0.54237288, 0.45833333],\n       [0.38888889, 0.375     , 0.54237288, 0.5       ],\n       [0.52777778, 0.375     , 0.55932203, 0.5       ],\n       [0.22222222, 0.20833333, 0.33898305, 0.41666667],\n       [0.38888889, 0.33333333, 0.52542373, 0.5       ],\n       [0.55555556, 0.54166667, 0.84745763, 1.        ],\n       [0.41666667, 0.29166667, 0.69491525, 0.75      ],\n       [0.77777778, 0.41666667, 0.83050847, 0.83333333],\n       [0.55555556, 0.375     , 0.77966102, 0.70833333],\n       [0.61111111, 0.41666667, 0.81355932, 0.875     ],\n       [0.91666667, 0.41666667, 0.94915254, 0.83333333],\n       [0.16666667, 0.20833333, 0.59322034, 0.66666667],\n       [0.83333333, 0.375     , 0.89830508, 0.70833333],\n       [0.66666667, 0.20833333, 0.81355932, 0.70833333],\n       [0.80555556, 0.66666667, 0.86440678, 1.        ],\n       [0.61111111, 0.5       , 0.69491525, 0.79166667],\n       [0.58333333, 0.29166667, 0.72881356, 0.75      ],\n       [0.69444444, 0.41666667, 0.76271186, 0.83333333],\n       [0.38888889, 0.20833333, 0.6779661 , 0.79166667],\n       [0.41666667, 0.33333333, 0.69491525, 0.95833333],\n       [0.58333333, 0.5       , 0.72881356, 0.91666667],\n       [0.61111111, 0.41666667, 0.76271186, 0.70833333],\n       [0.94444444, 0.75      , 0.96610169, 0.875     ],\n       [0.94444444, 0.25      , 1.        , 0.91666667],\n       [0.47222222, 0.08333333, 0.6779661 , 0.58333333],\n       [0.72222222, 0.5       , 0.79661017, 0.91666667],\n       [0.36111111, 0.33333333, 0.66101695, 0.79166667],\n       [0.94444444, 0.33333333, 0.96610169, 0.79166667],\n       [0.55555556, 0.29166667, 0.66101695, 0.70833333],\n       [0.66666667, 0.54166667, 0.79661017, 0.83333333],\n       [0.80555556, 0.5       , 0.84745763, 0.70833333],\n       [0.52777778, 0.33333333, 0.6440678 , 0.70833333],\n       [0.5       , 0.41666667, 0.66101695, 0.70833333],\n       [0.58333333, 0.33333333, 0.77966102, 0.83333333],\n       [0.80555556, 0.41666667, 0.81355932, 0.625     ],\n       [0.86111111, 0.33333333, 0.86440678, 0.75      ],\n       [1.        , 0.75      , 0.91525424, 0.79166667],\n       [0.58333333, 0.33333333, 0.77966102, 0.875     ],\n       [0.55555556, 0.33333333, 0.69491525, 0.58333333],\n       [0.5       , 0.25      , 0.77966102, 0.54166667],\n       [0.94444444, 0.41666667, 0.86440678, 0.91666667],\n       [0.55555556, 0.58333333, 0.77966102, 0.95833333],\n       [0.58333333, 0.45833333, 0.76271186, 0.70833333],\n       [0.47222222, 0.41666667, 0.6440678 , 0.70833333],\n       [0.72222222, 0.45833333, 0.74576271, 0.83333333],\n       [0.66666667, 0.45833333, 0.77966102, 0.95833333],\n       [0.72222222, 0.45833333, 0.69491525, 0.91666667],\n       [0.41666667, 0.29166667, 0.69491525, 0.75      ],\n       [0.69444444, 0.5       , 0.83050847, 0.91666667],\n       [0.66666667, 0.54166667, 0.79661017, 1.        ],\n       [0.66666667, 0.41666667, 0.71186441, 0.91666667],\n       [0.55555556, 0.20833333, 0.6779661 , 0.75      ],\n       [0.61111111, 0.41666667, 0.71186441, 0.79166667],\n       [0.52777778, 0.58333333, 0.74576271, 0.91666667],\n       [0.44444444, 0.41666667, 0.69491525, 0.70833333]])"
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Нормализация данных\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T06:45:38.718651600Z",
     "start_time": "2023-11-02T06:45:38.711072100Z"
    }
   },
   "id": "701607b732c689e2"
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_data = data.target\n",
    "y_train_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T06:45:38.930465400Z",
     "start_time": "2023-11-02T06:45:38.923567600Z"
    }
   },
   "id": "349ed47990933ae9"
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [
    {
     "data": {
      "text/plain": "[[1, 0, 0],\n [1, 0, 0],\n [1, 0, 0],\n [1, 0, 0],\n [1, 0, 0],\n [1, 0, 0],\n [1, 0, 0],\n [1, 0, 0],\n [1, 0, 0],\n [1, 0, 0],\n [1, 0, 0],\n [1, 0, 0],\n [1, 0, 0],\n [1, 0, 0],\n [1, 0, 0],\n [1, 0, 0],\n [1, 0, 0],\n [1, 0, 0],\n [1, 0, 0],\n [1, 0, 0],\n [1, 0, 0],\n [1, 0, 0],\n [1, 0, 0],\n [1, 0, 0],\n [1, 0, 0],\n [1, 0, 0],\n [1, 0, 0],\n [1, 0, 0],\n [1, 0, 0],\n [1, 0, 0],\n [1, 0, 0],\n [1, 0, 0],\n [1, 0, 0],\n [1, 0, 0],\n [1, 0, 0],\n [1, 0, 0],\n [1, 0, 0],\n [1, 0, 0],\n [1, 0, 0],\n [1, 0, 0],\n [1, 0, 0],\n [1, 0, 0],\n [1, 0, 0],\n [1, 0, 0],\n [1, 0, 0],\n [1, 0, 0],\n [1, 0, 0],\n [1, 0, 0],\n [1, 0, 0],\n [1, 0, 0],\n [0, 1, 0],\n [0, 1, 0],\n [0, 1, 0],\n [0, 1, 0],\n [0, 1, 0],\n [0, 1, 0],\n [0, 1, 0],\n [0, 1, 0],\n [0, 1, 0],\n [0, 1, 0],\n [0, 1, 0],\n [0, 1, 0],\n [0, 1, 0],\n [0, 1, 0],\n [0, 1, 0],\n [0, 1, 0],\n [0, 1, 0],\n [0, 1, 0],\n [0, 1, 0],\n [0, 1, 0],\n [0, 1, 0],\n [0, 1, 0],\n [0, 1, 0],\n [0, 1, 0],\n [0, 1, 0],\n [0, 1, 0],\n [0, 1, 0],\n [0, 1, 0],\n [0, 1, 0],\n [0, 1, 0],\n [0, 1, 0],\n [0, 1, 0],\n [0, 1, 0],\n [0, 1, 0],\n [0, 1, 0],\n [0, 1, 0],\n [0, 1, 0],\n [0, 1, 0],\n [0, 1, 0],\n [0, 1, 0],\n [0, 1, 0],\n [0, 1, 0],\n [0, 1, 0],\n [0, 1, 0],\n [0, 1, 0],\n [0, 1, 0],\n [0, 1, 0],\n [0, 1, 0],\n [0, 1, 0],\n [0, 1, 0],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1]]"
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = []\n",
    "for i in y_train_data:\n",
    "    if i == 0:\n",
    "        y_train.append([1, 0, 0])\n",
    "    if i == 1:\n",
    "        y_train.append([0, 1, 0])\n",
    "    if i == 2:\n",
    "        y_train.append([0, 0, 1])\n",
    "y_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T06:45:39.168023500Z",
     "start_time": "2023-11-02T06:45:39.164512700Z"
    }
   },
   "id": "3adb480f08f9a274"
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [],
   "source": [
    "def breaks_f():\n",
    "    ic(1)\n",
    "    ic(2)\n",
    "    exit(123)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T06:45:39.394558200Z",
     "start_time": "2023-11-02T06:45:39.390042900Z"
    }
   },
   "id": "33c9b0742ec0ffe4"
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "outputs": [],
   "source": [
    "class CounterPropagation:\n",
    "    def __init__(self, kohonen_neurons, grossberg_neurons, epoch, learning_rate_a, learning_rate_b):\n",
    "        self.kohonen_neurons = kohonen_neurons\n",
    "        self.grossberg_neurons = grossberg_neurons\n",
    "        self.epoch = epoch\n",
    "        self.learning_rate_a = learning_rate_a\n",
    "        self.learning_rate_b = learning_rate_b\n",
    "\n",
    "    def get_weight_w(self, X_train):\n",
    "        mass_weight = []\n",
    "        size = self.kohonen_neurons\n",
    "        for i in range(size):\n",
    "            vector = []\n",
    "            for j in range(size):\n",
    "                vector.append(1/2)\n",
    "            mass_weight.append(vector)\n",
    "        return mass_weight\n",
    "\n",
    "    def get_weight_v(self, y_train):\n",
    "        mass_weight = []\n",
    "        size = self.grossberg_neurons\n",
    "        for i in range(size):\n",
    "            vector = []\n",
    "            for j in range(self.kohonen_neurons):\n",
    "                vector.append(random.uniform(0, 0.25))\n",
    "            mass_weight.append(vector)\n",
    "        return mass_weight\n",
    "\n",
    "    def count_layer_kohonen(self, X_train, i):\n",
    "        result_kohonen_layer = []\n",
    "        # ic(X_train[i])\n",
    "        # ic(self.vector_weight_w[0])\n",
    "        # ic(np.dot(X_train[i], self.vector_weight_w))\n",
    "        for j, jj in enumerate(self.vector_weight_w):\n",
    "            value = 0\n",
    "            for index, index_value in enumerate(X_train[i]):\n",
    "                value += X_train[i][index] * self.vector_weight_w[j][index]\n",
    "            result_kohonen_layer.append(value)\n",
    "        # ic(result_kohonen_layer)\n",
    "        for i, ii in enumerate(result_kohonen_layer):\n",
    "            if i != np.argmax(result_kohonen_layer):\n",
    "                result_kohonen_layer[i] = 0\n",
    "\n",
    "        return result_kohonen_layer, np.argmax(result_kohonen_layer)\n",
    "\n",
    "    def count_layer_grossberg(self, X_train, i, kohonen_layer):\n",
    "        # ic(kohonen_layer)\n",
    "        # ic(self.vector_weight_v)\n",
    "        # ic(np.multiply(kohonen_layer, self.vector_weight_v))\n",
    "        result_layer_grossberg = []\n",
    "        for j, jj in enumerate(self.vector_weight_v):\n",
    "            value = 0\n",
    "            for index, index_value in enumerate(kohonen_layer):\n",
    "                value += kohonen_layer[index] * self.vector_weight_w[j][index]\n",
    "            result_layer_grossberg.append(value)\n",
    "        # ic(result_layer_grossberg)\n",
    "        return result_layer_grossberg\n",
    "\n",
    "    def weight_adjustment_kh(self, result_kohonen_layer, X_train, y_train):\n",
    "        for i, ii in enumerate(self.vector_weight_w):\n",
    "            for j, ii in enumerate(self.vector_weight_w[i]):\n",
    "                self.vector_weight_w[i][j] += self.learning_rate_a * (result_kohonen_layer[i] - self.vector_weight_w[i][j])\n",
    "        \n",
    "        \n",
    "        \n",
    "    def weight_adjustment_gr(self, result_kohonen_layer, result_layer_grossberg, X_train, y_train):\n",
    "        # ic(self.vector_weight_v)\n",
    "\n",
    "        for i, ii in enumerate(self.vector_weight_v):\n",
    "            for j, jj in enumerate(ii):\n",
    "                # ic(self.learning_rate)\n",
    "                # ic(y_train[i])\n",
    "                # ic(result_layer_grossberg[i])\n",
    "                # ic(result_kohonen_layer[j])\n",
    "                if result_kohonen_layer[j] != 0:\n",
    "                    self.vector_weight_v[i][j] += self.learning_rate_b * (y_train[i] - result_layer_grossberg[i]) * \\\n",
    "                                                  result_kohonen_layer[j]\n",
    "                else:\n",
    "                    self.vector_weight_v[i][j] += self.learning_rate_b * (y_train[i] - result_layer_grossberg[i])\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        self.vector_weight_w = self.get_weight_w(X_train=X_train)\n",
    "        self.vector_weight_v = self.get_weight_v(y_train=y_train)\n",
    "        # ic(self.vector_weight_w)\n",
    "        for e in range(self.epoch):\n",
    "            for i in range(X_train.shape[0]):\n",
    "                result_kohonen_layer, index_winning_neuron = self.count_layer_kohonen(X_train, i)\n",
    "                self.weight_adjustment_kh(result_kohonen_layer, X_train[i], y_train[i])\n",
    "                result_layer_grossberg = self.count_layer_grossberg(X_train, i, result_kohonen_layer)\n",
    "                self.weight_adjustment_gr(result_kohonen_layer, result_layer_grossberg, X_train[i], y_train[i])\n",
    "            self.learning_rate_b *= 0.9\n",
    "            # ic(self.vector_weight_w)\n",
    "            # ic(self.vector_weight_v)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        predictions = []\n",
    "        for i in range(X_test.shape[0]):\n",
    "            result_kohonen_layer, index_winning_neuron = self.count_layer_kohonen(X_test, i)\n",
    "            result_layer_grossberg = self.count_layer_grossberg(X_test, i, result_kohonen_layer)\n",
    "            predictions.append(result_layer_grossberg)\n",
    "        return predictions\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T06:46:27.613576700Z",
     "start_time": "2023-11-02T06:46:27.607871700Z"
    }
   },
   "id": "10946468544b032"
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "outputs": [],
   "source": [
    "cp_neurons = CounterPropagation(kohonen_neurons=4, grossberg_neurons=3, epoch=10, learning_rate_a=0.001, learning_rate_b=0.1)\n",
    "cp_neurons.train(X_train=X_train, y_train=y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T06:46:28.040723100Z",
     "start_time": "2023-11-02T06:46:27.981556100Z"
    }
   },
   "id": "9fd0ba3cc446fe84"
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "outputs": [
    {
     "data": {
      "text/plain": "[[0.024870881741486932, 0.024911492334254295, 0.33190227769942376],\n [0.018472814778696604, 0.018502978243186613, 0.24651998124946337],\n [0.018394635957463525, 0.018424671767119857, 0.24547668374578735],\n [0.017960828828765985, 0.017990156293425697, 0.2396875213190775],\n [0.02515039724237193, 0.025191464243975, 0.33563241611431055],\n [0.03629932324697145, 0.03635859485018344, 0.48441499540889116],\n [0.022004362706430906, 0.02204029268359314, 0.29364853958539383],\n [0.02379986478978633, 0.023838726565051985, 0.3176095409392645],\n [0.013907165456355591, 0.013929873868496617, 0.18559132479841084],\n [0.018404765452209006, 0.018434817801881505, 0.2456118620001378],\n [0.029638900750806677, 0.029687296836678274, 0.3955315605594516],\n [0.023008363338970727, 0.023045932705570378, 0.30704694259399207],\n [0.016059328854502272, 0.016085551441662883, 0.21431197657307965],\n [0.010575921200946388, 0.010593190167664, 0.14113582187592646],\n [0.033566307242817804, 0.03362111622178008, 0.4479428571792901],\n [0.04213732620066499, 0.0422061304277297, 0.5623232295313138],\n [0.033750483954959186, 0.033805593668150814, 0.4504006980750934],\n [0.02657001202877192, 0.02661339705828314, 0.35457719603644644],\n [0.03574938873262013, 0.035807762371423656, 0.47707611133570366],\n [0.030188835265157976, 0.03023812931543804, 0.4028704446326389],\n [0.027931706983429817, 0.027977315466047835, 0.3727490349636074],\n [0.030894094414648646, 0.03094454005225131, 0.412282138215414],\n [0.01974413540272231, 0.019776374751962835, 0.2634857734230688],\n [0.02989215979676244, 0.029940969418434125, 0.3989113062023447],\n [0.024919992807979928, 0.024960683592094846, 0.33255766559434036],\n [0.020461590061612075, 0.02049500091169781, 0.27306021625572324],\n [0.02783533518735938, 0.027880786308617834, 0.3714629519467594],\n [0.026222447201399334, 0.026265264707257333, 0.34993893837223417],\n [0.024591366240601934, 0.024631520424533593, 0.32817213928453703],\n [0.02030626542647273, 0.02033942265364433, 0.2709874067461357],\n [0.02002674992558773, 0.020059450743923624, 0.26725726833124896],\n [0.03005554791199366, 0.030104624323089208, 0.4010917229707538],\n [0.03048654374088033, 0.03053632390652199, 0.40684336856069764],\n [0.034685402253684605, 0.03474203855474292, 0.4628771963366016],\n [0.020103895739493997, 0.02013672252591035, 0.26828678033716047],\n [0.019900493045188466, 0.019932987704096346, 0.2655723684304208],\n [0.02709109446612121, 0.027135330348725673, 0.36153104872341824],\n [0.022736911318177604, 0.022774037442451274, 0.3034244114379269],\n [0.014263826771146855, 0.014287117560204045, 0.1903509752192091],\n [0.024514220426695665, 0.024554248642546867, 0.3271426272786255],\n [0.02521844656885952, 0.0252596246852801, 0.33654053536363604],\n [0.009720214730780854, 0.009736086451218678, 0.12971640661585876],\n [0.016251569046735515, 0.01627810553463521, 0.21687742472770444],\n [0.032227466899723695, 0.032280089743891106, 0.4300760133750524],\n [0.03443680484445524, 0.03449303522149952, 0.4595596603034594],\n [0.019457589429072254, 0.019489360889720572, 0.259661813247125],\n [0.02912691480087606, 0.02917447488691736, 0.38869910062906576],\n [0.01831749014355725, 0.018347399985133128, 0.24444717173987576],\n [0.02892454511389734, 0.02897177475918339, 0.3859984742200906],\n [0.02216878382898893, 0.022204982282328242, 0.2958427418515674],\n [0.07687951303590246, 0.07700504628512564, 1.0259582169326433],\n [0.0730180898557253, 0.07313731795316888, 0.9744274685666013],\n [0.07814483619448993, 0.07827243553546034, 1.0428439728429564],\n [0.051059739193806956, 0.05114311244517619, 0.6813929603828306],\n [0.07039417076446038, 0.07050911437730957, 0.9394112302224209],\n [0.060643855271612646, 0.060742878013784675, 0.8092931285000384],\n [0.07627115528990142, 0.07639569517793474, 1.0178396739854096],\n [0.03820961688726883, 0.03827200772677885, 0.5099078917556983],\n [0.06870413696459407, 0.06881632099396236, 0.9168577046419844],\n [0.053954077298538204, 0.05404217659007457, 0.7200179443853117],\n [0.036222907619006976, 0.036282054446427715, 0.48339522774496735],\n [0.06554693992658076, 0.06565396870473882, 0.8747248643609528],\n [0.048540255378704336, 0.04861951467334849, 0.6477704123143196],\n [0.06746869889033544, 0.06757886562602494, 0.9003707656156515],\n [0.055188482365470026, 0.05527859726393196, 0.73649109791388],\n [0.07183094551837092, 0.07194823517890094, 0.9585850101599644],\n [0.06531550248486194, 0.06542215335877864, 0.8716363283432181],\n [0.05271810961686039, 0.052804190749944795, 0.7035239377402857],\n [0.061650667203963304, 0.06175133392602327, 0.8227290483454024],\n [0.0497263667087319, 0.04980756275353639, 0.663599085223192],\n [0.07645533200204281, 0.07658017262430548, 1.020297514881213],\n [0.060315228704234634, 0.06041371484622341, 0.8049076021902349],\n [0.0678954755462679, 0.06800633914719753, 0.9060661062813042],\n [0.06307656717797112, 0.06317956219075166, 0.8417577041873584],\n [0.06536379622176619, 0.06547052595244812, 0.8722808089629139],\n [0.07012271874366725, 0.07023721911419048, 0.9357886990663559],\n [0.07211252703390952, 0.0722302764767817, 0.96234271957038],\n [0.07975772418044996, 0.07988795713682083, 1.0643679864174815],\n [0.06717905389470495, 0.0672887476815426, 0.8965054489464144],\n [0.04718662390413832, 0.047263672912185396, 0.6297061806459803],\n [0.04738093011102517, 0.04745829639331777, 0.6322991997961339],\n [0.045044590000737114, 0.04511814137378077, 0.6011207071256618],\n [0.054841950545424234, 0.05493149960698618, 0.7318666257474321],\n [0.0707137008444197, 0.07082916620418922, 0.9436753637756384],\n [0.06388679121104328, 0.06399110920378888, 0.8525701556644962],\n [0.07384753987096161, 0.07396812234164936, 0.9854964910546755],\n [0.07544170527466511, 0.07556489078945426, 1.0067706514973354],\n [0.05932342358109392, 0.05942029024716789, 0.7916719484315162],\n [0.059368402618279685, 0.05946534272868832, 0.7922721943353749],\n [0.05304748146939562, 0.05313410041960736, 0.707919409891326],\n [0.05489106161191724, 0.05498069086482673, 0.7325220136423488],\n [0.0678253602051267, 0.06793610931773236, 0.9051304160364496],\n [0.05448528923063297, 0.054574255915278744, 0.7271069753266338],\n [0.03793010138638382, 0.037992035817058144, 0.5061777533408114],\n [0.05702399902789976, 0.05711711106254973, 0.7609860944060812],\n [0.0590208377909071, 0.059117210377662516, 0.7876339366711627],\n [0.059726096940397766, 0.05982362111447578, 0.7970456302539377],\n [0.06393508494794752, 0.06403948179745836, 0.853214636284192],\n [0.04041970011715761, 0.04048569970648857, 0.5394014845253422],\n [0.058095015979600366, 0.058189876831752044, 0.7752788311662405],\n [0.09984705557450621, 0.10001009153580037, 1.3324604053534566],\n [0.07438238043245597, 0.07450383622128597, 0.9926339461079842],\n [0.0951465562842549, 0.09530191700248918, 1.2697321741240615],\n [0.08142881972032169, 0.08156178133670351, 1.0866687806435094],\n [0.09192234292708079, 0.09207243896604056, 1.2267050000914688],\n [0.10317880322982305, 0.10334727945852067, 1.3769226261550123],\n [0.05874391791209491, 0.05883983832829423, 0.7839384368704982],\n [0.09303284485043652, 0.09318475418020941, 1.241524664371265],\n [0.08158517736278784, 0.08171839428883701, 1.0887553756508612],\n [0.10989507954307631, 0.11007452249040924, 1.466551431003898],\n [0.086051355867078, 0.08619186542385694, 1.1483565925917727],\n [0.07994293389991815, 0.08007346927727159, 1.0668396128110493],\n [0.09045465008151461, 0.09060234958797189, 1.2071186177721807],\n [0.0727422029842399, 0.07286098059788061, 0.9707457542637012],\n [0.08387190300667527, 0.08400885382864579, 1.1192717625473456],\n [0.09170881073802976, 0.09185855810946489, 1.2238554099303784],\n [0.08321419230893162, 0.0833500691834007, 1.1104946037430294],\n [0.11418046807937508, 0.11436690845327722, 1.5237400031988269],\n [0.10522756435913425, 0.10539938592173538, 1.4042633731517762],\n [0.06340800504515998, 0.06351154124857429, 0.8461807473339278],\n [0.09782942821458873, 0.09798916967897195, 1.3055351389609813],\n [0.07437225093771051, 0.07449369018652434, 0.992498767853634],\n [0.10084349612686178, 0.10100815913306369, 1.3457579189823043],\n [0.07498060868371155, 0.07510304129371524, 1.0006173108008678],\n [0.09399632750399439, 0.09414981006314005, 1.2543823543624613],\n [0.09338847315790098, 0.09354096317783682, 1.2462705292942988],\n [0.07462291436159348, 0.07474476290792778, 0.995843874882305],\n [0.07653351082327586, 0.07665847910037221, 1.0213408123848888],\n [0.08624669508129167, 0.08638752359906934, 1.1509633972396907],\n [0.0867280506617362, 0.08686966516433166, 1.1573870944448592],\n [0.09317803999083038, 0.09333018640350126, 1.2434622956265022],\n [0.11029928930961458, 0.11047939227368483, 1.4719456162031552],\n [0.08794582536857666, 0.08808942832309818, 1.1736383155767134],\n [0.07215150860565703, 0.0722693216998606, 0.9628629292109462],\n [0.07022197388398005, 0.07033663632395161, 0.9371132603539535],\n [0.10410537032628701, 0.10427535950653245, 1.3892876775011713],\n [0.0965929571330033, 0.0967506796169545, 1.289034414436884],\n [0.08349370780981663, 0.0836300410931214, 1.1142247421579163],\n [0.07518194536336346, 0.07530470672736918, 1.0033041517120784],\n [0.09152566703321521, 0.0916751153571742, 1.2214113545323397],\n [0.09646876626725763, 0.09662628596528726, 1.2873770855315845],\n [0.093012298138776, 0.09316417391870742, 1.2412504682060368],\n [0.07438238043245597, 0.07450383622128597, 0.9926339461079842],\n [0.09838949222368552, 0.09855014819249337, 1.313009201288519],\n [0.10079284865313436, 0.10095742895925543, 1.3450820277105522],\n [0.09122692555016607, 0.09137588607201023, 1.2174246451065167],\n [0.07532920651841093, 0.07545220833882106, 1.0052693539628443],\n [0.08470082341449241, 0.08483912774493392, 1.1303337174167267],\n [0.09290505156280285, 0.09305675222441447, 1.2398192610936016],\n [0.07637921919546334, 0.07650393553639878, 1.0192817883730658]]"
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_pred = cp_neurons.predict(X_test=X_train)\n",
    "x_test_pred"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T06:46:28.353641400Z",
     "start_time": "2023-11-02T06:46:28.276482900Z"
    }
   },
   "id": "1168053f39e7af91"
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "outputs": [
    {
     "data": {
      "text/plain": "[[0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1],\n [0, 0, 1]]"
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_pred_norm = x_test_pred\n",
    "for i, ii in enumerate(x_test_pred_norm):\n",
    "    print(x_test_pred_norm)\n",
    "    # print(x_test_pred_norm[i])\n",
    "    for j, jj in enumerate(x_test_pred_norm[i]):\n",
    "        if jj != max(x_test_pred_norm[i]):\n",
    "            x_test_pred_norm[i][j] = 0\n",
    "        else:\n",
    "            x_test_pred_norm[i][j] = 1\n",
    "x_test_pred_norm"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T06:46:32.888983900Z",
     "start_time": "2023-11-02T06:46:32.878433Z"
    }
   },
   "id": "d6d2968b9297cf15"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-02T06:28:32.227923600Z"
    }
   },
   "id": "90bfa702c1982f86"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
