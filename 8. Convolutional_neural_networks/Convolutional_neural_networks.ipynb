{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T12:44:03.744359800Z",
     "start_time": "2023-11-14T12:44:03.722481200Z"
    }
   },
   "id": "f681d0ab70ce4cc3"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def get_train_data():\n",
    "    data_train = pd.read_csv('../Datasets/Fashion MNIST/fashion-mnist_train.csv')\n",
    "    X_train = data_train.drop(['label'], axis=1).to_numpy()\n",
    "    X_train = X_train.reshape((X_train.shape[0], 28, 28, 1))\n",
    "\n",
    "    y_train = data_train['label'].to_numpy()\n",
    "\n",
    "    # One-hot encode the labels\n",
    "    encoder = OneHotEncoder(sparse=False)\n",
    "    y_train_onehot = encoder.fit_transform(y_train.reshape(-1, 1))\n",
    "\n",
    "    return X_train, y_train_onehot"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T12:44:03.781352Z",
     "start_time": "2023-11-14T12:44:03.739353700Z"
    }
   },
   "id": "6fdf40b516648e65"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def print_accuracy(model, X_test, y_test):\n",
    "    predictions = model.predict(X_test)\n",
    "    predicted_labels = np.argmax(predictions, axis=1)\n",
    "    true_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "    accuracy = np.mean(predicted_labels == true_labels)\n",
    "    print(f\"Final Accuracy: {accuracy * 100:.2f}%\")\n",
    "    return predictions"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T12:44:03.783353Z",
     "start_time": "2023-11-14T12:44:03.753353600Z"
    }
   },
   "id": "df5c3edcb9356878"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "class CNN:\n",
    "    def __init__(self, input_size, num_classes, count_convolutional_layer):\n",
    "        self.input_size = input_size\n",
    "        self.num_classes = num_classes  # Update the initialization\n",
    "        self.count_convolutional_layer = count_convolutional_layer\n",
    "        self.weight_count_convolutional = self.get_weight_count_convolutional()\n",
    "        self.flatten_weight = self.get_flatten_weight()\n",
    "\n",
    "    def get_flatten_weight(self):\n",
    "        flatten_weight = []\n",
    "        for i in range(self.num_classes):\n",
    "            mask = []\n",
    "            for j in range(49):\n",
    "                mask.append(random.uniform(0, 1))\n",
    "            flatten_weight.append(mask)\n",
    "        return np.array(flatten_weight)\n",
    "\n",
    "    def get_weight_count_convolutional(self):\n",
    "        return np.random.uniform(0, 1, size=(3, 3))\n",
    "\n",
    "    def flatten(self, input_data):\n",
    "        return input_data.reshape(-1)\n",
    "\n",
    "    def convolve2d(self, input_data):\n",
    "        channels = 1  # Default value for single channel\n",
    "        if len(input_data.shape) == 2:\n",
    "            height, width = input_data.shape\n",
    "            input_data = input_data.reshape((height, width, 1))\n",
    "        elif len(input_data.shape) == 3:\n",
    "            height, width, channels = input_data.shape\n",
    "        else:\n",
    "            raise ValueError(\"Input data should be either 2D or 3D\")\n",
    "\n",
    "        mask = np.zeros((height + 2, width + 2, channels))\n",
    "        mask[1:height + 1, 1:width + 1, :] = input_data\n",
    "        output_data = []\n",
    "        for i in range(1, height + 1):\n",
    "            s_array = []\n",
    "            for j in range(1, width + 1):\n",
    "                summ = 0\n",
    "                for ii in range(-1, 2):\n",
    "                    for jj in range(-1, 2):\n",
    "                        summ += np.sum(mask[i + ii, j + jj, :] * self.weight_count_convolutional[ii + 1][jj + 1])\n",
    "                s_array.append(summ)\n",
    "            output_data.append(s_array)\n",
    "        return np.array(output_data)\n",
    "\n",
    "    def max_pooling(self, data):\n",
    "        leng = len(data)\n",
    "        i = 0\n",
    "        j = 0\n",
    "        result = []\n",
    "        while i < leng:\n",
    "            result_str = []\n",
    "            while j < leng:\n",
    "                result_str.append(max([data[i][j], data[i][j + 1], data[i + 1][j], data[i + 1][j + 1]]))\n",
    "                j += 2\n",
    "            i += 2\n",
    "            j = 0\n",
    "            result.append(result_str)\n",
    "        return np.array(result)\n",
    "\n",
    "    def fully_connected(self, flattened_output):\n",
    "        return np.dot(self.flatten_weight, flattened_output)\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-np.clip(x, -500, 500)))\n",
    "\n",
    "    def train(self, X, y, epoch, learning_rate=0.01):\n",
    "        for eph in range(epoch):\n",
    "            for index_training_example, training_example in enumerate(X):\n",
    "                training_example = np.array(training_example)\n",
    "                conv1_output = self.convolve2d(training_example)\n",
    "                pool1_output = self.max_pooling(conv1_output)\n",
    "\n",
    "                conv2_output = self.convolve2d(pool1_output)\n",
    "                pool21_output = self.max_pooling(conv2_output)\n",
    "\n",
    "                flattened_output = self.flatten(pool21_output)\n",
    "                fully_connected = self.fully_connected(flattened_output)\n",
    "                output = self.sigmoid(fully_connected)\n",
    "\n",
    "                # Backward pass\n",
    "                loss_gradient = output - y[index_training_example]\n",
    "                fc_output_gradient = np.dot(self.flatten_weight.T, loss_gradient)\n",
    "                fc_output_gradient[fc_output_gradient < 0] = 0\n",
    "\n",
    "                # Update weights\n",
    "                self.flatten_weight -= learning_rate * np.outer(loss_gradient, flattened_output)\n",
    "\n",
    "                # Optionally, update convolutional layer weights here\n",
    "\n",
    "                # Print or log the loss\n",
    "                if index_training_example % 1000 == 0:\n",
    "                    current_loss = np.mean(\n",
    "                        -y_train * np.log(output + 1e-10) - (1 - y_train) * np.log(1 - output + 1e-10))\n",
    "                    print(f'Epoch {eph}, Example {index_training_example}, Loss: {current_loss}')\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for example in X:\n",
    "            conv1_output = self.convolve2d(example)\n",
    "            pool1_output = self.max_pooling(conv1_output)\n",
    "\n",
    "            conv2_output = self.convolve2d(pool1_output)\n",
    "            pool2_output = self.max_pooling(conv2_output)\n",
    "\n",
    "            flattened_output = self.flatten(pool2_output)\n",
    "            fully_connected = self.fully_connected(flattened_output)\n",
    "            output = self.sigmoid(fully_connected)\n",
    "            predictions.append(output)\n",
    "\n",
    "        return np.array(predictions)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T12:44:03.784353200Z",
     "start_time": "2023-11-14T12:44:03.778353100Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\PycharmProjects\\Design_and_training_neural_networks\\venv\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Example 0, Loss: 20.72326583693641\n",
      "Epoch 0, Example 1000, Loss: 4.138992645620313\n",
      "Epoch 0, Example 2000, Loss: 4.1446531673072835\n",
      "Epoch 0, Example 3000, Loss: 2.3025850929040477\n",
      "Epoch 0, Example 4000, Loss: 4.139760173984649\n",
      "Epoch 0, Example 5000, Loss: 4.1456125777627015\n",
      "Epoch 0, Example 6000, Loss: 2.3025850929040477\n",
      "Epoch 0, Example 7000, Loss: 4.1456125777627015\n",
      "Epoch 0, Example 8000, Loss: 2.3025850929040477\n",
      "Epoch 0, Example 9000, Loss: 4.147723280764621\n",
      "Epoch 0, Example 10000, Loss: 5.98585777230064\n",
      "Epoch 0, Example 11000, Loss: 4.148778632265584\n",
      "Epoch 0, Example 12000, Loss: 4.142158700123195\n",
      "Epoch 0, Example 13000, Loss: 4.1446531673072835\n",
      "Epoch 0, Example 14000, Loss: 2.3025850929040477\n",
      "Epoch 0, Example 15000, Loss: 4.138992645620313\n",
      "Epoch 0, Example 16000, Loss: 4.1446531673072835\n",
      "Epoch 0, Example 17000, Loss: 7.82936496238701\n",
      "Epoch 0, Example 18000, Loss: 5.985282126027394\n",
      "Epoch 0, Example 19000, Loss: 5.991710176078698\n",
      "Epoch 0, Example 20000, Loss: 4.1456125777627015\n",
      "Epoch 0, Example 21000, Loss: 4.139760173984649\n",
      "Epoch 0, Example 22000, Loss: 4.147723280764621\n",
      "Epoch 0, Example 23000, Loss: 5.987296887983769\n",
      "Epoch 0, Example 24000, Loss: 5.982020130478971\n",
      "Epoch 0, Example 25000, Loss: 4.146955752400287\n",
      "Epoch 0, Example 26000, Loss: 4.143214051624153\n",
      "Epoch 0, Example 27000, Loss: 4.138992645620313\n",
      "Epoch 0, Example 28000, Loss: 4.148682691220039\n",
      "Epoch 0, Example 29000, Loss: 4.148682691220039\n",
      "Epoch 0, Example 30000, Loss: 4.1446531673072835\n",
      "Epoch 0, Example 31000, Loss: 5.984898361845224\n",
      "Epoch 0, Example 32000, Loss: 4.1446531673072835\n",
      "Epoch 0, Example 33000, Loss: 4.148682691220039\n",
      "Epoch 0, Example 34000, Loss: 4.148778632265584\n",
      "Epoch 0, Example 35000, Loss: 4.1456125777627015\n",
      "Epoch 0, Example 36000, Loss: 4.138992645620313\n",
      "Epoch 0, Example 37000, Loss: 2.3025850929040477\n",
      "Epoch 0, Example 38000, Loss: 4.1446531673072835\n",
      "Epoch 0, Example 39000, Loss: 5.983363305116556\n",
      "Epoch 0, Example 40000, Loss: 5.989311649940149\n",
      "Epoch 0, Example 41000, Loss: 2.3025850929040477\n",
      "Epoch 0, Example 42000, Loss: 4.148682691220039\n",
      "Epoch 0, Example 43000, Loss: 2.3025850929040477\n",
      "Epoch 0, Example 44000, Loss: 2.3025850929040477\n",
      "Epoch 0, Example 45000, Loss: 4.148682691220039\n",
      "Epoch 0, Example 46000, Loss: 4.147723280764621\n",
      "Epoch 0, Example 47000, Loss: 2.3025850929040477\n",
      "Final Accuracy: 64.78%\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    X_train, y_train = get_train_data()\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "    simple_conv_net = CNN(\n",
    "        input_size=X_train[0].shape[0],\n",
    "        num_classes=y_train.shape[1],  # Update the number of classes based on one-hot encoding shape\n",
    "        count_convolutional_layer=1)\n",
    "    simple_conv_net.train(X=X_train, y=y_train, epoch=1)\n",
    "    print_accuracy(simple_conv_net, X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T13:23:49.686536600Z",
     "start_time": "2023-11-14T12:44:03.787353Z"
    }
   },
   "id": "2c9ef49157b13d9"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Example 0, Loss: 4.138992645620313\n",
      "Epoch 0, Example 1000, Loss: 4.138992645620313\n",
      "Epoch 0, Example 2000, Loss: 4.1446531673072835\n",
      "Epoch 0, Example 3000, Loss: 2.3025850929040477\n",
      "Epoch 0, Example 4000, Loss: 4.139760173984649\n",
      "Epoch 0, Example 5000, Loss: 4.1456125777627015\n",
      "Epoch 0, Example 6000, Loss: 2.3025850929040477\n",
      "Epoch 0, Example 7000, Loss: 2.3025850929040477\n",
      "Epoch 0, Example 8000, Loss: 2.3025850929040477\n",
      "Epoch 0, Example 9000, Loss: 4.147723280764621\n",
      "Epoch 0, Example 10000, Loss: 4.139760173984649\n",
      "Epoch 0, Example 11000, Loss: 4.148778632265584\n",
      "Epoch 0, Example 12000, Loss: 4.142158700123195\n",
      "Epoch 0, Example 13000, Loss: 4.1446531673072835\n",
      "Epoch 0, Example 14000, Loss: 4.142158700123195\n",
      "Epoch 0, Example 15000, Loss: 4.138992645620313\n",
      "Epoch 0, Example 16000, Loss: 2.3025850929040477\n",
      "Epoch 0, Example 17000, Loss: 5.987296887983769\n",
      "Epoch 0, Example 18000, Loss: 5.985282126027394\n",
      "Epoch 0, Example 19000, Loss: 4.148682691220039\n",
      "Epoch 0, Example 20000, Loss: 4.1456125777627015\n",
      "Epoch 0, Example 21000, Loss: 4.139760173984649\n",
      "Epoch 0, Example 22000, Loss: 5.993916820126157\n",
      "Epoch 0, Example 23000, Loss: 5.987296887983769\n",
      "Epoch 0, Example 24000, Loss: 5.982020130478971\n",
      "Epoch 0, Example 25000, Loss: 4.146955752400287\n",
      "Epoch 0, Example 26000, Loss: 2.3025850929040477\n",
      "Epoch 0, Example 27000, Loss: 4.138992645620313\n",
      "Epoch 0, Example 28000, Loss: 5.98825629843919\n",
      "Epoch 0, Example 29000, Loss: 4.148682691220039\n",
      "Epoch 0, Example 30000, Loss: 5.985282126027394\n",
      "Epoch 0, Example 31000, Loss: 5.984898361845224\n",
      "Epoch 0, Example 32000, Loss: 4.1446531673072835\n",
      "Epoch 0, Example 33000, Loss: 4.148682691220039\n",
      "Epoch 0, Example 34000, Loss: 5.993916820126157\n",
      "Epoch 0, Example 35000, Loss: 4.1456125777627015\n",
      "Epoch 0, Example 36000, Loss: 4.138992645620313\n",
      "Epoch 0, Example 37000, Loss: 2.3025850929040477\n",
      "Epoch 0, Example 38000, Loss: 4.1446531673072835\n",
      "Epoch 0, Example 39000, Loss: 4.138992645620313\n",
      "Epoch 0, Example 40000, Loss: 4.148682691220039\n",
      "Epoch 0, Example 41000, Loss: 2.3025850929040477\n",
      "Epoch 0, Example 42000, Loss: 4.142158700123195\n",
      "Epoch 0, Example 43000, Loss: 2.3025850929040477\n",
      "Epoch 0, Example 44000, Loss: 4.138992645620313\n",
      "Epoch 0, Example 45000, Loss: 4.148682691220039\n",
      "Epoch 0, Example 46000, Loss: 4.147723280764621\n",
      "Epoch 0, Example 47000, Loss: 2.3025850929040477\n",
      "Final Accuracy: 63.63%\n"
     ]
    }
   ],
   "source": [
    "simple_conv_net.train(X=X_train, y=y_train, epoch=1)\n",
    "print_accuracy(simple_conv_net, X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T14:04:17.738951200Z",
     "start_time": "2023-11-14T13:24:50.957816100Z"
    }
   },
   "id": "65d12e5c98ec4ce3"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "def count_error(answers_data, predict_data):\n",
    "    mse = mean_squared_error(answers_data, predict_data)\n",
    "    r2 = r2_score(answers_data, predict_data)\n",
    "    mae = mean_absolute_error(answers_data, predict_data)\n",
    "\n",
    "    print(f'Mean Squared Error: {mse}')\n",
    "    print(f'R-squared: {r2}')\n",
    "    print(f'Mean Absolute Error: {mae}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T14:04:17.755621300Z",
     "start_time": "2023-11-14T14:04:17.741949800Z"
    }
   },
   "id": "351b622eb3c849db"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d787f790af7007bd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
